{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Recruitment Analysis\n",
    "\n",
    "A simple script to test for anomalies within recruitment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing the necessary libraries for this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import statsmodels.api as sm\n",
    "import math\n",
    "import matplotlib.pyplot as plt\n",
    "from scipy import stats\n",
    "from statsmodels.graphics.regressionplots import abline_plot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import the recruitment file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "recruitment = pd.read_csv(\"recruitment.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing for those who are unable to commit 1 year to PV\n",
    "\n",
    "\n",
    "The idea is simple, just checked who did not tick yes to the commitment question in the google form."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we aim to clean the table to remove unnecessary columns for easier viewing:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dropping unnecessary columns such as tag number, year of study, graduating\n",
    "del recruitment['Tag Number']\n",
    "del recruitment['1h) As of August 2021, what year of study would you be in?']\n",
    "del recruitment['1i) Will you be graduating before Jun 2022?']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We check for those that have not checked for the commitments section:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# first let me check what is the data type for the column\n",
    "recruitment['1j) Should you be accepted into Protege Ventures, would you be able to commit to sessions on a weekly basis for the next 12 months? Sessions will be suspended during exam season.'].dtype\n",
    "\n",
    "# so it is a string basically, okay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "unavailable = recruitment.loc[recruitment['1j) Should you be accepted into Protege Ventures, would you be able to commit to sessions on a weekly basis for the next 12 months? Sessions will be suspended during exam season.'] != 'checked']\n",
    "len(unavailable)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since everyone can commit to PV, seeing that there are 0 people who unchecked, this column is also unnecessary, and can be removed to save columns, together with the next column:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "del recruitment['1j) Should you be accepted into Protege Ventures, would you be able to commit to sessions on a weekly basis for the next 12 months? Sessions will be suspended during exam season.']\n",
    "del recruitment['1k) What other commitments might you have for the next 12 months? (ie CCA Clubs, Freelance work, etc)']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test: Testing for lenient assessors\n",
    "\n",
    "This idea revolves around generating average word count for each score, for each question.\n",
    "\n",
    "I.e. for question 1, average word count for score 1, 2, 3, 4, 5 is maybe 50, 100, 150, 200, 250, through counting each word in the answer, and plotting a regression. We continue this for each question.\n",
    "\n",
    "We can see thus who tends to grade above / below the mean scores for several questions, and flag them out for being lenient.\n",
    "\n",
    "We would also need to run a hypothesis test to prove that this is the case actually, that we can in fact, use word count as a way to determine potential score one should received."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We need to clean up the table, so let's check what the type of the scores is, and change it to integers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dtype('O')"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find a random variable\n",
    "variable = recruitment.iloc[0, [3]]\n",
    "variable.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# now we clean for all the columns that have scores present in them\n",
    "\n",
    "# firstly we start by creating a column list with the relevant numbers needed\n",
    "column_list = [3, 4, 6, 7, 9, 10, 12, 13, 21, 22, 24, 25]\n",
    "\n",
    "# now loop through the column:\n",
    "for index in column_list:\n",
    "    \n",
    "    # loop through each cell in each column\n",
    "    for i, row_value in recruitment.iloc[:, [index]].iterrows():\n",
    "        \n",
    "        # change the values to strings so that you can remove extra comments\n",
    "        recruitment.iloc[i, [index]] = recruitment.iloc[i, [index]].astype(str)\n",
    "        \n",
    "        # now remove any newlines from the cells\n",
    "        recruitment.iloc[i, [index]] = recruitment.iloc[i, [index]].replace('\\n','', regex=True)\n",
    "        \n",
    "        # because some scores have ranknigs attached to them, i.e. applicant 67: 2: I don't see much .... score\n",
    "        # so we have to remove this, by taking the first score attached, i.e. take 2 and filter out the rest\n",
    "        recruitment.iloc[i, [index]] = recruitment.iloc[i, [index]].str[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert the strings into integers because it doesn't work by iloc somehow    \n",
    "recruitment[recruitment.columns[column_list]] = recruitment[recruitment.columns[column_list]].apply(pd.to_numeric, errors = 'coerce')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we try to split up each part, and create tables to store the text count for each answer of each applicant, for each question in a table:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_list = [3, 4, 6, 7, 9, 10, 12, 13, 21, 22, 24, 25]\n",
    "\n",
    "# creating the various tables for the various questions\n",
    "question_one = recruitment.iloc[:, [0, 1, 2, 3, 4]].copy()\n",
    "question_two = recruitment.iloc[:, [0, 1, 5, 6, 7]].copy()\n",
    "question_three = recruitment.iloc[:, [0, 1, 8, 9, 10]].copy()\n",
    "question_four = recruitment.iloc[:, [0, 1, 11, 12, 13]].copy()\n",
    "question_five = recruitment.iloc[:, [0, 1, 20, 21, 22]].copy()\n",
    "question_six = recruitment.iloc[:, [0, 1, 23, 24, 25]].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'wordcount' from 'leniency' (unknown location)",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-12-dcae6cd7f26a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[1;32mfrom\u001b[0m \u001b[0mleniency\u001b[0m \u001b[1;32mimport\u001b[0m \u001b[0mwordcount\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m \u001b[0mwordcount\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mquestion_one\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[0mquestion_one\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mImportError\u001b[0m: cannot import name 'wordcount' from 'leniency' (unknown location)"
     ]
    }
   ],
   "source": [
    "from leniency import wordcount\n",
    "\n",
    "\n",
    "wordcount(question_one)\n",
    "question_one"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
